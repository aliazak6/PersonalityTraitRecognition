{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de2037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5995/5995 [21:01<00:00,  4.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Paths in Google Drive\n",
    "base_path = 'C:/Users/myldr/Desktop/CS559_Proj/Dataset/First_Impressions_V2/'\n",
    "\n",
    "# Set paths\n",
    "video_folder = base_path + 'Training_Data/Videos'\n",
    "annotation_path = base_path + 'Training_Data/Annotations/annotation_training.pkl'\n",
    "save_folder = base_path + 'Processed_Training_Data_2'\n",
    "\n",
    "def extract_frames(video_path, num_frames, frames_per_second=1):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    target_frame_indices = [int(frame_rate * i) for i in range(5)]\n",
    "\n",
    "    for idx in target_frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    frame = cv2.resize(frame, (224, 224))\n",
    "    frame = tf.keras.applications.resnet.preprocess_input(frame)\n",
    "    return frame\n",
    "\n",
    "def process_video(video_file, video_folder, all_annotations, num_frames):\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    frames = extract_frames(video_path, num_frames)\n",
    "    processed_frames = [preprocess_frame(frame) for frame in frames]\n",
    "    base_name = os.path.basename(video_file)\n",
    "\n",
    "    if all(base_name in all_annotations[trait] for trait in all_annotations.keys()):\n",
    "        # Retrieve only the first 5 labels from the annotations\n",
    "        annotation = [all_annotations[trait][base_name] for trait in all_annotations.keys()][:5]\n",
    "        return processed_frames, annotation\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# Load annotations\n",
    "with open(annotation_path, 'rb') as file:\n",
    "    all_annotations = pickle.load(file, encoding='latin1')\n",
    "\n",
    "# Create save folder if it doesn't exist\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "# Adjust the number of frames here to reduce the size\n",
    "num_frames = 5\n",
    "\n",
    "# Main processing loop\n",
    "all_video_data, all_video_labels = [], []\n",
    "all_video_files = os.listdir(video_folder)\n",
    "errors = []\n",
    "\n",
    "for video_file in tqdm(all_video_files):\n",
    "    X_batch, y_batch = process_video(video_file, video_folder, all_annotations, num_frames)\n",
    "    if X_batch is not None and y_batch is not None:\n",
    "        all_video_data.append(X_batch)\n",
    "        all_video_labels.append(y_batch)\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "all_video_data = np.array(all_video_data)\n",
    "all_video_labels = np.array(all_video_labels)\n",
    "np.save(os.path.join(save_folder, 'preprocessed_tarining_batch_final5.npy'), all_video_data)\n",
    "np.save(os.path.join(save_folder, 'labels_tarining_batch_final5.npy'), all_video_labels)\n",
    "\n",
    "# Error reporting\n",
    "if errors:\n",
    "    print(\"Errors during processing:\")\n",
    "    for video_file, error_message in errors:\n",
    "        print(f\"Video: {video_file}, Error: {error_message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6738cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1999/1999 [06:52<00:00,  4.84it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Paths in Google Drive\n",
    "base_path = 'C:/Users/myldr/Desktop/CS559_Proj/Dataset/First_Impressions_V2/'\n",
    "\n",
    "# Set paths\n",
    "video_folder = base_path + 'Validation_Data/Videos'\n",
    "annotation_path = base_path + 'Validation_Data/Annotations/annotation_validation.pkl'\n",
    "save_folder = base_path + 'Processed_Validation_Data_2'\n",
    "\n",
    "def extract_frames(video_path, num_frames, frames_per_second=1):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    target_frame_indices = [int(frame_rate * i) for i in range(5)]\n",
    "\n",
    "    for idx in target_frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    frame = cv2.resize(frame, (224, 224))\n",
    "    frame = tf.keras.applications.resnet.preprocess_input(frame)\n",
    "    return frame\n",
    "\n",
    "def process_video(video_file, video_folder, all_annotations, num_frames):\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    frames = extract_frames(video_path, num_frames)\n",
    "    processed_frames = [preprocess_frame(frame) for frame in frames]\n",
    "    base_name = os.path.basename(video_file)\n",
    "\n",
    "    if all(base_name in all_annotations[trait] for trait in all_annotations.keys()):\n",
    "        # Retrieve only the first 5 labels from the annotations\n",
    "        annotation = [all_annotations[trait][base_name] for trait in all_annotations.keys()][:5]\n",
    "        return processed_frames, annotation\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# Load annotations\n",
    "with open(annotation_path, 'rb') as file:\n",
    "    all_annotations = pickle.load(file, encoding='latin1')\n",
    "\n",
    "# Create save folder if it doesn't exist\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "# Adjust the number of frames here to reduce the size\n",
    "num_frames = 5\n",
    "\n",
    "# Main processing loop\n",
    "all_video_data, all_video_labels = [], []\n",
    "all_video_files = os.listdir(video_folder)\n",
    "errors = []\n",
    "\n",
    "for video_file in tqdm(all_video_files):\n",
    "    X_batch, y_batch = process_video(video_file, video_folder, all_annotations, num_frames)\n",
    "    if X_batch is not None and y_batch is not None:\n",
    "        all_video_data.append(X_batch)\n",
    "        all_video_labels.append(y_batch)\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "all_video_data = np.array(all_video_data)\n",
    "all_video_labels = np.array(all_video_labels)\n",
    "np.save(os.path.join(save_folder, 'validaiton_videos_final5.npy'), all_video_data)\n",
    "np.save(os.path.join(save_folder, 'validaiton_labels_final5.npy'), all_video_labels)\n",
    "\n",
    "# Error reporting\n",
    "if errors:\n",
    "    print(\"Errors during processing:\")\n",
    "    for video_file, error_message in errors:\n",
    "        print(f\"Video: {video_file}, Error: {error_message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8daf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Data Shape: (1999, 5, 224, 224, 3)\n",
      "Labels Shape: (1999, 5)\n"
     ]
    }
   ],
   "source": [
    "# Paths in Google Drive\n",
    "base_path = 'C:/Users/myldr/Desktop/CS559_Proj/Dataset/First_Impressions_V2/'\n",
    "\n",
    "save_folder = base_path + 'Processed_Validation_Data_2'\n",
    "\n",
    "# Load the saved data with allow_pickle=True\n",
    "loaded_data = np.load(os.path.join(save_folder, 'validaiton_videos_final5.npy'), allow_pickle=True)\n",
    "loaded_labels = np.load(os.path.join(save_folder, 'validaiton_labels_final5.npy'), allow_pickle=True)\n",
    "\n",
    "# Print the shapes\n",
    "print(\"Video Data Shape:\", loaded_data.shape)\n",
    "print(\"Labels Shape:\", loaded_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8907eaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Data Shape: (5995, 5, 224, 224, 3)\n",
      "Labels Shape: (5995, 5)\n"
     ]
    }
   ],
   "source": [
    "# Paths in Google Drive\n",
    "base_path = 'C:/Users/myldr/Desktop/CS559_Proj/Dataset/First_Impressions_V2/'\n",
    "\n",
    "save_folder = base_path + 'Processed_Training_Data_2'\n",
    "\n",
    "\n",
    "# Load the saved data with allow_pickle=True\n",
    "loaded_data = np.load(os.path.join(save_folder, 'preprocessed_tarining_batch_final5.npy'), allow_pickle=True)\n",
    "loaded_labels = np.load(os.path.join(save_folder, 'labels_tarining_batch_final5.npy'), allow_pickle=True)\n",
    "\n",
    "# Print the shapes\n",
    "print(\"Video Data Shape:\", loaded_data.shape)\n",
    "print(\"Labels Shape:\", loaded_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b56b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
