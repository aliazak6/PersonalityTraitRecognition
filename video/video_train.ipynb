{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc9e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TRAINING CODE##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d68246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_batch is reshaped to treat each frame as an independent sample, \n",
    "# changing its shape from (batch_size, 5, 224, 224, 3) to (batch_size * 5, 224, 224, 3).\n",
    "# y_batch is repeated 5 times (for each frame),\n",
    "# so each set of 5 frames from the same video has the same label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from vit_keras import vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths \n",
    "base_path = 'C:/Users/myldr/Desktop/CS559_Proj/Dataset/First_Impressions_V2/'\n",
    "\n",
    "train_data_path = base_path + 'Processed_Training_Data_2/preprocessed_tarining_batch_final5.npy'\n",
    "train_labels_path = base_path + 'Processed_Training_Data_2/labels_tarining_batch_final5.npy'\n",
    "\n",
    "val_data_path = base_path + 'Processed_Validation_Data_2/validaiton_videos_final5.npy'\n",
    "val_labels_path = base_path + 'Processed_Validation_Data_2/validaiton_labels_final5.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if not physical_devices:\n",
    "    print(\"No GPU detected. Training on CPU.\")\n",
    "else:\n",
    "    print(\"GPU detected. Training on GPU.\")\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalityAnalysisModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(PersonalityAnalysisModel, self).__init__()\n",
    "        # Define the Vision Transformer model\n",
    "        self.vit_model = vit.vit_b16(\n",
    "            image_size=224,\n",
    "            activation='sigmoid',\n",
    "            pretrained=True,\n",
    "            include_top=False,\n",
    "            pretrained_top=False\n",
    "        )\n",
    "        # Freeze the pre-trained layers\n",
    "        for layer in self.vit_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "        self.output_layer = tf.keras.layers.Dense(5, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.vit_model(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = PersonalityAnalysisModel()\n",
    "\n",
    "# Compile the model as before\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TensorBoard for monitoring (logs will be stored in Google Drive)\n",
    "log_dir = base_path + \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f837a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Callbacks\n",
    "checkpoint_path = base_path + 'best_model_subclass'  # Updated path without .h5 extension\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    save_format=\"tf\"  # Save in TensorFlow SavedModel format\n",
    ")\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3  # Reduced patience for early stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9264bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator function\n",
    "def data_generator(data_path, labels_path, batch_size):\n",
    "    while True:\n",
    "        X = np.load(data_path, mmap_mode='r')\n",
    "        y = np.load(labels_path, mmap_mode='r')\n",
    "\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for start_idx in range(0, len(X), batch_size):\n",
    "            end_idx = min(start_idx + batch_size, len(X))\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "\n",
    "            X_batch = X[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "\n",
    "            # Reshape X_batch to have each frame as a separate sample\n",
    "            # And repeat y_batch accordingly\n",
    "            X_batch_reshaped = X_batch.reshape(-1, X_batch.shape[2], X_batch.shape[3], X_batch.shape[4])\n",
    "            y_batch_repeated = np.repeat(y_batch, X_batch.shape[1], axis=0)\n",
    "\n",
    "            yield X_batch_reshaped, y_batch_repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ef4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the data generator for training and validation\n",
    "batch_size = 32  # Increased batch size\n",
    "train_gen = data_generator(train_data_path, train_labels_path, batch_size)\n",
    "val_gen = data_generator(val_data_path, val_labels_path, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "try:\n",
    "  history = model.fit(\n",
    "      train_gen,\n",
    "      steps_per_epoch=len(np.load(train_data_path, mmap_mode='r')) // batch_size,\n",
    "      epochs=10,\n",
    "      validation_data=val_gen,\n",
    "      validation_steps=len(np.load(val_data_path, mmap_mode='r')) // batch_size,\n",
    "      verbose=1,\n",
    "      callbacks=[tensorboard_callback, checkpoint_callback, early_stopping_callback]\n",
    "  )\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
